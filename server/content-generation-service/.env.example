# Server Configuration
PORT=3009 # Example port for Content Generation Service

# LLM Configuration (Choose one provider and fill in details)
# Set LLM_PROVIDER to "openai", "claude", "gemini", or "ollama"
LLM_PROVIDER="openai" # Default to openai

# --- OpenAI ---
OPENAI_API_KEY="" # Replace with your actual key
OPENAI_MODEL_NAME="gpt-4o" # Or gpt-4, gpt-3.5-turbo, etc.

# --- Claude ---
CLAUDE_API_KEY="" # Replace with your actual key
CLAUDE_MODEL_NAME="claude-3-opus-20240229" # Or another Claude model

# --- Gemini ---
GEMINI_API_KEY="" # Replace with your actual key
GEMINI_MODEL_NAME="gemini-1.5-pro" # Or another Gemini model

# --- Ollama ---
OLLAMA_BASE_URL="http://localhost:11434/api" # Default Ollama API endpoint
OLLAMA_MODEL_NAME="llama3" # Or other model pulled in Ollama

# --- Redis Caching ---
REDIS_URL="redis://localhost:6379" # Redis server for caching
CACHE_TTL=3600 # Cache TTL in seconds (1 hour default)

# --- Content Safety ---
CONTENT_SAFETY_ENABLED=true # Enable content safety filtering
MIN_QUALITY_SCORE=0.7 # Minimum quality score for generated content (0.0-1.0)