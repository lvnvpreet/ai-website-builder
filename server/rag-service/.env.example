# Server Configuration
PORT=3008

# --- Pinecone Configuration ---
PINECONE_API_KEY="your-pinecone-api-key"
# Use PINECONE_INDEX_HOST for Serverless indexes
PINECONE_INDEX_HOST="your-pinecone-index-host"
# Use PINECONE_ENVIRONMENT for Pod-based indexes (e.g., gcp-starter, us-west1-gcp)
# PINECONE_ENVIRONMENT="your-pod-environment"
PINECONE_INDEX_NAME="your-index-name"
PINECONE_NAMESPACE="default"  # Optional namespace for partitioning index

# --- Embedding Model ---
EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_DIMENSION=384  # Dimension for the embedding model

# --- Reranker Model ---
RERANKER_ENABLED=true
RERANKER_MODEL_NAME="cross-encoder/ms-marco-MiniLM-L-6-v2"

# --- Chunking Configuration ---
DEFAULT_CHUNK_SIZE=512
DEFAULT_CHUNK_OVERLAP=50
TEXT_CHUNK_SIZE=512
CODE_CHUNK_SIZE=256
PDF_CHUNK_SIZE=512
EXCEL_CHUNK_SIZE=256

# --- Query Expansion ---
QUERY_EXPANSION_ENABLED=true
QUERY_EXPANSION_METHOD="keyword"  # Options: keyword, embeddings

# --- Metrics and Logging ---
METRICS_ENABLED=true
LOG_LEVEL=INFO